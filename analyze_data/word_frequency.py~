import nltk
import pickle
import numpy as np
import matplotlib.pyplot as plt
from wordcloud import WordCloud, ImageColorGenerator
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.decomposition import LatentDirichletAllocation

#extract prepocessed data from pickle files

#title_file = open("/home/francesita/Menopause/data_guardian/decades_pp/decades.pkl", "rb")
text_file = open("/media/francesita/Expansion Drive/Menopause/code/webscraper/blogs_articles/articles/body_preprocessed_tknzd.pkl", "rb")

#dic_file = open("/home/francesita/Menopause/data_guardian/decades_pp/decades.pkl", "rb")
documents = pickle.load(text_file)
#titles = pickle.load(title_file)

'''
dic = pickle.load(dic_file)

def extract_tokens(dic):
    
    #Get tokens from dictionary
    
    tokens = []
    for key in dic:
        tokens.append(dic[key]['tokens'])
    return tokens



documents = extract_tokens(dic)
'''

tfidf_vec_text = TfidfVectorizer(tokenizer=lambda i:i, min_df = 5, max_df = 0.95,lowercase = False)
tfidf_text_features = tfidf_vec_text.fit_transform(documents)

#testing numpy sort tfidf
tfidf_feat_array = tfidf_text_features.toarray()

#numpy array of the top n weights (the rest is zero)
tfidf_trunc = np.zeros(tfidf_feat_array.shape)

n = 300
for i_doc in range(tfidf_feat_array.shape[0]):
    #array of sorted indexes ordered by tfidf value
    sorted_per_doc = tfidf_feat_array[i_doc,:].argsort()[::-1]
    for i_best in range(n):
        tfidf_trunc[i_doc,sorted_per_doc[i_best]] = tfidf_feat_array[i_doc,sorted_per_doc[i_best]]

tfidf_text_vocab = np.array(tfidf_vec_text.get_feature_names())
tfidf_sorted_text_weights = np.argsort(tfidf_trunc.sum(axis=0))[::-1]

#################################COUNTVECTORIZER##########################################################################
count_vec_text = CountVectorizer(tokenizer=lambda i:i, min_df = 5, max_df = 0.95, lowercase = False)
count_text_features = count_vec_text.fit_transform(documents)

count_text_vocab = np.array(count_vec_text.get_feature_names())
count_sorted_text_weights = np.argsort(count_text_features.toarray().sum(axis=0))[::-1]


#n assigned at top
#top_n_text_count = count_text_vocab[count_sorted_text_weights][:n]


#top_n_title_tfidf = tfidf_title_vocab[tfidf_sorted_title_weights][:n]


def make_wordcloud(top_n_words, backgound_color = 'white', max_words = 50 , width = 400, height = 400, random_state=1):
    '''
    Generated word cloud from a list of top n number of words.
    Params:
        numpy array top_n_words: numpy_array of words
        string background color
        int max_no_words for word cloud
        int width, height and random_state
    '''
    #generate word cloud from most common words
    wc_text = ' '.join([word for word in top_n_words.tolist()])

    wc = WordCloud(background_color="white", max_words = max_words, width = width, height = height
                   ,random_state=random_state).generate(wc_text)

    plt.imshow(wc)
    plt.axis("off")
    plt.title('Top 50 words')
    plt.show()


def make_barchart(title, vocab, weights, x_label='Weights', y_label='Vocabulary', align = 'center', alpha=0.5):
    '''
    Make bar chart of word frequency of top n words
    String x_label, y_label, title
    tuple vocab
    list weights
    String align
    float alpha
    '''
    y_pos = np.arange(len(vocab))

    plt.barh(y_pos, weights, align = align, alpha=alpha)
    plt.yticks(y_pos, vocab)
    plt.xlabel(x_label)
    #plt.ylabel(y_label)
    plt.title(title)

    plt.show()


#calling make__bar chart with vocab, weights params given
top_n_text_count = count_text_vocab[count_sorted_text_weights][:n]
top_n_text_tfidf = tfidf_text_vocab[tfidf_sorted_text_weights][:n]

vocab_tfidf = top_n_text_tfidf[:15].tolist()
weights_tfidf = np.sort(tfidf_trunc.sum(axis=0))[::-1][:15].tolist()
title_tfidf = 'Top 15 words using tfidf'


vocab_count = top_n_text_count[:15].tolist()
weights_count = np.sort(count_text_features.toarray().sum(axis=0))[::-1][:15].tolist()
title_count = 'Top 15 words using Count'

make_barchart(title_count, tuple(vocab_count), weights_count, x_label='Frequency')
make_barchart( title_tfidf, tuple(vocab_tfidf), weights_tfidf)
make_wordcloud(top_n_text_tfidf)
